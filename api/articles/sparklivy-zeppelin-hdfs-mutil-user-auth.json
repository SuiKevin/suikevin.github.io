{"title":"关于`SparkLivy`和`ZeppelinNotebook`访问`HDFS`时的多用户权限控制","uid":"fa8de5b59170093e2dea98ffe77b6754","slug":"sparklivy-zeppelin-hdfs-mutil-user-auth","date":"2017-12-09T09:29:08.000Z","updated":"2025-03-22T07:26:18.891Z","comments":true,"path":"api/articles/sparklivy-zeppelin-hdfs-mutil-user-auth.json","keywords":null,"cover":null,"content":"<h1 id=\"关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制\"><a href=\"#关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制\" class=\"headerlink\" title=\"关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制\"></a>关于<code>SparkLivy</code>和<code>ZeppelinNotebook</code>访问<code>HDFS</code>时的多用户权限控制</h1><p><code>SparkLivy</code>在<code>Yarn</code>上运行应用时，默认使用的用户是<code>Livy</code>。</p>\n<p><code>ZeppelinNotebook</code>在使用<code>%Spark</code>等非<code>%Livy</code>的Interpreter时，使用的用户是<code>Zeppelin</code>。</p>\n<p><code>Livy</code>和<code>Zeppelin</code>用户默认在HDFS上的用户组是<code>hdfs</code>，默认具有<code>HDFS</code>上所有目录及文件的<code>r-x</code>权限。</p>\n<p>这样就会存在以下问题。</p>\n<h2 id=\"问题一：多用户\"><a href=\"#问题一：多用户\" class=\"headerlink\" title=\"问题一：多用户\"></a>问题一：多用户</h2><h3 id=\"描述\"><a href=\"#描述\" class=\"headerlink\" title=\"描述\"></a>描述</h3><p>所有用户在使用<code>SparkLivy</code>或者使用<code>Zeppelin</code>时都使用的是同一个用户（<code>Livy</code>或<code>Zeppelin</code>），<br>这样就无法控制用户应用（代码级别）对HDFS的访问权限，所有用户都使用的是<code>Livy</code>或<code>Zeppelin</code>的用户权限。</p>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><p><strong>SparkLivy</strong></p>\n<p>在创建<code>batch</code>或者<code>session</code>的时候添加<code>proxyUser</code>参数，指定当前用户。<br>详见：<a href=\"https://livy.incubator.apache.org/docs/latest/rest-api.html\">SparkLivy REST API</a></p>\n<p><strong>ZeppelinNotebook</strong></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>关于ZeppelinNotebook自身的多用户配置，请阅读本人的另一篇文章<a href=\"http://www.kevinsui.com/posts/ambari_zeppelin_shiro/\">配置Zeppelin使用Apache Shiro进行鉴权（多用户登录）</a>。</p></blockquote>\n<p>當把interpreter設定為isolated的時候某方面的確達到了多使用者共同使用Zeppelin的環境<br>(<a href=\"https://github.com/apache/zeppelin/blob/5e0aacf8a8f187702452d7cd2ee83b26c56dec90/docs/manual/userimpersonation.md\">详细Zeppelin配置</a>)，<br>但是那只限於Zeppelin這個平台本身，後來遇到了Zeppelin所有使用者在YARN裏面會用相同user啟動的狀況，<br>這樣一來對於使用者的追蹤變的困難。</p>\n<p>後來找了一下Zeppelin的討論目前對於使用者權限區隔的問題，Zeppelin採用Livy這個Spark Proxy當作解決方案，<br>再搭配Zeppelin內建的Livy Interpreter，能夠對Zeppelin的使用者做到區隔的動作。<br>(转自：<a href=\"http://terrence.logdown.com/posts/1172854-zeppelin-livy-server-supports-multiple-users-review\">Zeppelin 支援多用戶-Livy Server篇</a>)</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>目前仍存在一个问题，在作者<code>qwemicheal</code>的文章<br><a href=\"http://blog.csdn.net/qwemicheal/article/details/70306104\">Zeppelin 和livy结合实现代理用户中如何代理ldap邮箱用户</a><br>中提到<code>“使用zeppelin+livy的方式实现用户代理和后台权限控制．优点在于livy支持cluster模式 并seesion 客户端一段时间(默认６０分钟)不活动会自动中止spark任务”</code>。但是当多用户同时使用时，仍然会出现Spark集群无资源可用的情况。<br>那么就需要将session客户端的终止时间缩短。本人经过多次试验终究没有设置成功，最终在Web项目中添加轮询线程，调用SparkLivy的API结束掉<br>状态为Idle的session，以释放Spark集群资源。</p></blockquote>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>经过以上方法，解决了多用户的用户隔离问题，以及Zeppelin资源占用问题。但轮询线程仍然会消耗系统资源，未能找到最优解决方案。<br>希望有想法的道友能指点一二。</p>\n<h2 id=\"问题二：HDFS用户权限\"><a href=\"#问题二：HDFS用户权限\" class=\"headerlink\" title=\"问题二：HDFS用户权限\"></a>问题二：HDFS用户权限</h2><p>问题一结果了多用户的问题，使Web项目的用户可以和Hadoop生态关联，但仍未控制用户在Hadoop平台上的权限（<strong>本文仅介绍关于HDFS的权限控制</strong>）。</p>\n<h3 id=\"解决方案-1\"><a href=\"#解决方案-1\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><p><strong>启用HDFS的ACLs</strong></p>\n<p>在hdfs-site.xml文件中添加配置项，以在HDFS上启用ACL：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">  &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt;</span><br><span class=\"line\">  &lt;value&gt;true&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br></pre></td></tr></table></figure>\n\n<p>将此属性设置为“true”以启用对ACL的支持。ACL默认是禁用的。当禁用ACL时，NameNode拒绝所有对ACL的设置。</p>\n<p><strong>使用CLI命令创建和列出ACLs</strong></p>\n<p>两个新的子命令被添加到FsShell：<code>setfacl</code>和<code>getfacl</code>。这些命令是在相同的Linux shell命令之后建模的，但实现的标志较少。如果需要，可以稍后添加对其他标志的支持。</p>\n<ul>\n<li><strong>setfacl</strong></li>\n</ul>\n<p>设置文件和目录的ACL。</p>\n<p>例：</p>\n<p>-setfacl [-bkR] {-m | -x} <acl_spec> &lt;path&gt;</p>\n<p>-setfacl –set <acl_spec> &lt;path&gt;</p>\n<p>选项：</p>\n<p><strong>表6.1. ACL选项</strong></p>\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-b</td>\n<td>删除所有条目，但保留基本ACL条目。“用户”，“组”和“其他”的条目保留为与“权限位”兼容。</td>\n</tr>\n<tr>\n<td>-k</td>\n<td>删除默认ACL。</td>\n</tr>\n<tr>\n<td>-R</td>\n<td>将操作递归地应用于所有文件和目录。</td>\n</tr>\n<tr>\n<td>-m</td>\n<td>修改ACL。新的条目被添加到ACL中，并保留现有的条目。</td>\n</tr>\n<tr>\n<td>-x</td>\n<td>删除指定的ACL条目。所有其他ACL条目都保留。</td>\n</tr>\n<tr>\n<td>–set</td>\n<td>完全替换ACL并放弃所有现有的条目。acl_spec必须包含User，Group和Others的条目，以便与Permission Bits兼容。</td>\n</tr>\n<tr>\n<td><acl_spec></td>\n<td>逗号分隔的ACL条目列表。</td>\n</tr>\n<tr>\n<td>&lt;path&gt;</td>\n<td>要修改的文件或目录的路径。</td>\n</tr>\n</tbody></table>\n<p>例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hdfs dfs -setfacl -m user:hadoop:rw- /file</span><br><span class=\"line\">hdfs dfs -setfacl -x user:hadoop /file</span><br><span class=\"line\">hdfs dfs -setfacl -b /file</span><br><span class=\"line\">hdfs dfs -setfacl -k /dir</span><br><span class=\"line\">hdfs dfs -setfacl --set user::rw-,user:hadoop:rw-,group::r--,other::r-- /file</span><br><span class=\"line\">hdfs dfs -setfacl -R -m user:hadoop:r-x /dir</span><br><span class=\"line\">hdfs dfs -setfacl -m default:user:hadoop:r-x /dir</span><br></pre></td></tr></table></figure>\n\n<p><strong>退出代码：</strong></p>\n<p>成功返回0，错误返回非零。</p>\n<ul>\n<li><strong>getfacl</strong></li>\n</ul>\n<p>显示文件和目录的ACL。如果某个目录具有默认ACL，则getfacl还会显示默认ACL。</p>\n<p>用法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-getfacl [-R] &lt;path&gt;</span><br></pre></td></tr></table></figure>\n\n<p>选项：<br>​<br><strong>表6.2. getfacl选项</strong></p>\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>-R</td>\n<td>以递归方式列出所有文件和目录的ACL。</td>\n</tr>\n<tr>\n<td>&lt;path&gt;</td>\n<td>要列出的文件或目录的路径。</td>\n</tr>\n</tbody></table>\n<p>例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hdfs dfs -getfacl /file</span><br><span class=\"line\">hdfs dfs -getfacl -R /dir</span><br></pre></td></tr></table></figure>\n\n<p><strong>退出代码：</strong></p>\n<p>成功返回0，错误返回非零。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>为每个用户指定需要访问的目录或者文件，指定文件的ACL时，需要指定所有父级目录的ACL！！！</strong></p></blockquote>\n","text":"关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制SparkLivy在Yarn上运行应用时，默认使用的用户是Livy。 Ze...","permalink":"/post/sparklivy-zeppelin-hdfs-mutil-user-auth","photos":[],"count_time":{"symbolsCount":"2.7k","symbolsTime":"2 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Zeppelin","slug":"Zeppelin","count":3,"path":"api/tags/Zeppelin.json"},{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"},{"name":"SparkLivy","slug":"SparkLivy","count":1,"path":"api/tags/SparkLivy.json"},{"name":"Zeppelin Notebook","slug":"Zeppelin-Notebook","count":1,"path":"api/tags/Zeppelin-Notebook.json"},{"name":"HDFS","slug":"HDFS","count":1,"path":"api/tags/HDFS.json"},{"name":"Mutil User","slug":"Mutil-User","count":1,"path":"api/tags/Mutil-User.json"},{"name":"Auth","slug":"Auth","count":1,"path":"api/tags/Auth.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%85%B3%E4%BA%8ESparkLivy%E5%92%8CZeppelinNotebook%E8%AE%BF%E9%97%AEHDFS%E6%97%B6%E7%9A%84%E5%A4%9A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6\"><span class=\"toc-text\">关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%98%E4%B8%80%EF%BC%9A%E5%A4%9A%E7%94%A8%E6%88%B7\"><span class=\"toc-text\">问题一：多用户</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%8F%8F%E8%BF%B0\"><span class=\"toc-text\">描述</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88\"><span class=\"toc-text\">解决方案</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">总结</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%98%E4%BA%8C%EF%BC%9AHDFS%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90\"><span class=\"toc-text\">问题二：HDFS用户权限</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-1\"><span class=\"toc-text\">解决方案</span></a></li></ol></li></ol></li></ol>","author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Ubuntu/Python 结巴分词 + Word2Vec利用维基百科训练词向量","uid":"882d31fc168f9dee83d771cd41dd9d18","slug":"jieba-word2vec","date":"2024-11-18T05:40:13.000Z","updated":"2025-03-22T07:26:06.962Z","comments":true,"path":"api/articles/jieba-word2vec.json","keywords":null,"cover":null,"text":"Ubuntu/Python 结巴分词 + Word2Vec利用维基百科训练词向量结巴分词是一个跨语言的中文分词器，整体效果还算不错，功能也够用，这里直接用Pyt...","permalink":"/post/jieba-word2vec","photos":[],"count_time":{"symbolsCount":"10k","symbolsTime":"9 mins."},"categories":[{"name":"NLP","slug":"NLP","count":2,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":2,"path":"api/tags/NLP.json"},{"name":"Jieba","slug":"Jieba","count":2,"path":"api/tags/Jieba.json"},{"name":"Word2Vec","slug":"Word2Vec","count":1,"path":"api/tags/Word2Vec.json"},{"name":"Linux","slug":"Linux","count":3,"path":"api/tags/Linux.json"},{"name":"Ubuntu","slug":"Ubuntu","count":1,"path":"api/tags/Ubuntu.json"},{"name":"Python","slug":"Python","count":1,"path":"api/tags/Python.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Hadoop生态部分组件介绍","uid":"f600e8de35fac4a36aec15d10c646ff1","slug":"hadoop-components","date":"2017-10-09T07:51:17.000Z","updated":"2025-03-22T07:26:00.505Z","comments":true,"path":"api/articles/hadoop-components.json","keywords":null,"cover":null,"text":"Apache Hadoop Apache Hadoop是一款支持数据密集型分布式应用程序并以Apache 2.0许可协议发布的开源软件框架。它支持在商品硬件构建...","permalink":"/post/hadoop-components","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Zeppelin","slug":"Zeppelin","count":3,"path":"api/tags/Zeppelin.json"},{"name":"Shiro","slug":"Shiro","count":2,"path":"api/tags/Shiro.json"},{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"},{"name":"Spark","slug":"Spark","count":1,"path":"api/tags/Spark.json"},{"name":"Livy","slug":"Livy","count":1,"path":"api/tags/Livy.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}