[{"id":"b99718bea3cc16756aa515dc86531783","title":"windows系统刻录光盘教程_刻录系统光盘教程-CSDN博客【转载】","content":"windows系统刻录光盘教程_刻录系统光盘教程-CSDN博客\n\n\n\n\n\n\n\n\nExcerpt文章浏览阅读1.2k次，点赞9次，收藏7次。工作中如果有重要资料需要刻录成光盘该如何操作呢？请参考下面的文章。本文介绍两种刻录方式系统下直接刻录和使用软件UltraISO（软碟通）刻录_刻录系统光盘教程\n\n欲买桂花同载酒、  于 2024-12-13 13:59:19 发布\n工作中如果有重要资料需要刻录成光盘该如何操作呢？请参考下面的文章。本文介绍两种刻录方式系统下直接刻录和使用软件UltraISO（软碟通）刻录。\n系统刻录这种方式刻录比较简单，无需安装任何软件，直接在系统下进行操作即可\n首先插入刻录机，并且插入光盘。打开此电脑，这时会在这里看到新的DVD驱动器，双击选择该[驱动器]\n如图下所示，设置一个标题，选中用于CD&#x2F;DVD播放机，点击下一页\n然后此时光盘里面有个desktop.ini的文件，不用管，或者删除也行。把需要刻录的文件拖进来（不要超过光盘的最大容量）\n如下图所示，把需要刻录的文件拖进来之后，右键空白处，点击刻录到光盘。\n注意：如果是DVD-R（一次性写入）的光盘的话，执行该操作后将无法再次写入数据到该光盘，该光盘数据已经固定死。即使空间未全部用完，也无法继续写入数据。\n设置好光盘标题和刻录速度后，点击下一步\n稍微等待一会\n刻录好之后，光盘会自动弹出，然后出现图下所示提示，点击取消\n此时驱动器图标如图下所示\n再插上已刻录好的光盘后，驱动器图标如图下所示\n双击运行驱动器，可以看到文件已经成功写入到光盘中~\nUltraISO（软碟通）刻录这种方式刻录稍微复杂一点点。但是可以手动选择写入速度和写入方式等相关参数。具体操作请见下面。\n双击打开软件\n如图下所示，在下面的本地目录找到需要刻录的文件所在位置\n把需要刻录的文件拖进上方的位置，右键空白处，点击全部选择\n然后点击图下所示位置按钮\n出现图下所示界面，选择好刻录机、写入速度、写入方式，然后点击刻录\n注意：这里的写入速度可以不选择最快，选择低速一点写入，防止写入速度过快导致光盘写坏或者刻录机故障\n稍微等待一会\n刻录成功之后，界面会提示“刻录成功”，然后光盘会从刻录机中弹出。点击返回，关闭该界面\n此时再把光盘插入刻录机，双击打开DVD RW驱动器\n此时可以看到已经成功刻录到光盘中的文件\n","slug":"windows-disc-burning","date":"2025-03-22T06:49:32.000Z","categories_index":"Tools","tags_index":"Windows,Disc Burning","author_index":"Kevin"},{"id":"34e2a32717145682320598ec6f8d1d99","title":"Compile and Install OpenCC on Minimal CentOS 7","content":"Compile and Install OpenCC on Minimal CentOS 7測試過程在虛擬機中進行，使用vm搭建，操作系統版本CentOS Linux release 7.2.1511 (Core)，內核版本3.10.0-327.10.1.el7.x86_64。\nDownloading &amp; Uncompressing\nOpenCC代碼開源，公佈在GitHub上，地址 https://github.com/BYVoid/OpenCC，使用wegt命令下載，保存路徑爲/usr/local/src。\n執行命令\n123sudo wget https://github.com/BYVoid/OpenCC/archive/master.zip#重命名sudo mv master.zip opencc.zip\n文件是zip格式壓縮包，需要安裝unzip命令，否則會報錯\n1-bash: unzip: command not found\n\n執行命令\n1sudo yum -y install unzip\n執行unzip命令解壓到當前目錄\n123456sudo unzip opencc.zip[vagrant@opencc src]$ ls -lhtotal 1.8Mdrwxr-xr-x. 9 root root 4.0K Mar 10 21:57 OpenCC-master-rw-r--r--. 1 root root 1.8M Mar 22 21:05 opencc.zip[vagrant@opencc src]$\n\nCompilation\n編譯主要2步：make, make install，提示gcc 4.6 is required。\n安裝OpenCC需安裝以下依賴包\n1sudo yum install -y cmake gcc gcc-c++ doxygen\n爲/usr/lib/libopencc.so.2`創建符號鏈接至&#x2F;usr&#x2F;lib64&#x2F;libopencc.so.2&#96;\n以下是摸索過程\nError1\n進入目錄後，執行sudo make，報錯\n1cmake: command not found\n安裝cmake解決，執行命令\n1sudo yum install -y cmake\nError2\n再次執行sudo make，報錯\n1CMake Error: CMAKE_CXX_COMPILER not set\n因已安裝gcc，故安裝gcc-c++，執行命令\n1sudo yum install -y gcc-c++\nError3\n報錯\n1Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE)\n安裝doxygen，執行命令\n1sudo yum install -y doxygen\n再次執行sudo make，正常編譯\n執行make make install安裝\n123[vagrant@opencc OpenCC-master]$ which opencc/usr/bin/opencc[vagrant@opencc OpenCC-master]$\nError4\n執行命令opencc --help報錯\n1opencc: error while loading shared libraries: libopencc.so.2: cannot open shared object file: No such file or directory\n查找文件libopencc.so.2\n123[vagrant@opencc OpenCC-master]$ sudo find / -name libopencc.so.2/usr/local/src/OpenCC-master/build/rel/src/libopencc.so.2/usr/lib/libopencc.so.2\n根據繁体转简体，CentOS安装OpenCC，升级到gcc4.6，創建符號鏈接至&#x2F;usr&#x2F;lib64&#x2F;目錄下\n12345[vagrant@opencc OpenCC-master]$ sudo ln -s /usr/lib/libopencc.so.2 /usr/lib64/libopencc.so.2[vagrant@opencc OpenCC-master]$ opencc --versionOpen Chinese Convert (OpenCC) Command Line ToolVersion: 1.0.3[vagrant@opencc OpenCC-master]$\n成功安裝\nError5执行\n1opencc -i wiki.zh.text -o wiki.zh.text.jian -c zht2zhs.ini\n报错\n1PARSE JSON ERROR\nuse xxx.json file instead of xxx.ini\n1opencc -i wiki.zh.text -o wiki.zh.text.jian -c t2s.json\nexample dir -&gt; &#x2F;usr&#x2F;share&#x2F;opencc&#x2F;\nUsage\n123456789101112131415161718Usage:   opencc  [--noflush &lt;bool&gt;] [-i &lt;file&gt;] [-o &lt;file&gt;] [-c &lt;file&gt;] [--]           [--version] [-h]Options:   --noflush &lt;bool&gt;     Disable flush for every line   -i &lt;file&gt;,  --input &lt;file&gt;     Read original text from &lt;file&gt;.   -o &lt;file&gt;,  --output &lt;file&gt;     Write converted text to &lt;file&gt;.   -c &lt;file&gt;,  --config &lt;file&gt;     Configuration file   --,  --ignore_rest     Ignores the rest of the labeled arguments following this flag.   --version     Displays version information and exits.   -h,  --help     Displays usage information and exits.\n\n-i: 指定輸入文件\n-o: 指定轉換後的輸出文件\n-c: 指定配置文件，以何種形式轉換\n\n配置文件有如下幾種：\n\ns2t.json Simplified Chinese to Traditional Chinese 簡體到繁體\nt2s.json Traditional Chinese to Simplified Chinese 繁體到簡體\ns2tw.json Simplified Chinese to Traditional Chinese (Taiwan Standard) 簡體到臺灣正體\ntw2s.json Traditional Chinese (Taiwan Standard) to Simplified Chinese 臺灣正體到簡體\ns2hk.json Simplified Chinese to Traditional Chinese (Hong Kong Standard) 簡&gt;體到香港繁體（香港小學學習字詞表標準）\nhk2s.json Traditional Chinese (Hong Kong Standard) to Simplified Chinese 香&gt;港繁體（香港小學學習字詞表標準）到簡體\ns2twp.json Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom 簡體到繁體（臺灣正體標準）並轉* 換爲臺灣常用詞彙\ntw2sp.json Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom 繁體（臺灣正體標準）到簡* 體並轉換爲中國大陸常用詞彙\nt2tw.json Traditional Chinese (OpenCC Standard) to Taiwan Standard 繁體（OpenCC 標準）到臺灣正體\nt2hk.json Traditional Chinese (OpenCC Standard) to Hong Kong Standard 繁體（OpenCC 標準）到香港繁體（香港小學學習字詞表標準）\n\nUsage Example\nExample1\n使用配置文件tw2s將正體文件轉換爲簡體\n123456789101112[vagrant@opencc tmp]$ lstw.txt[vagrant@opencc tmp]$ cat tw.txt昨夜西風凋碧樹，獨上高樓，望盡天涯路[vagrant@opencc tmp]$ opencc -i tw.txt -o cn.txt -c tw2s[vagrant@opencc tmp]$ lscn.txt  tw.txt[vagrant@opencc tmp]$ cat cn.txt昨夜西风凋碧树，独上高楼，望尽天涯路[vagrant@opencc tmp]$ cat tw.txt昨夜西風凋碧樹，獨上高樓，望盡天涯路[vagrant@opencc tmp]$\nExample2\n使用管道符|\n12345[vagrant@opencc tmp]$ cat tw.txt昨夜西風凋碧樹，獨上高樓，望盡天涯路[vagrant@opencc tmp]$ cat tw.txt | opencc -c tw2s昨夜西风凋碧树，独上高楼，望尽天涯路[vagrant@opencc tmp]$\n\nReferences\n\nOpen Chinese Convert\n繁体转简体，CentOS安装OpenCC，升级到gcc4.6\nCompile and Install OpenCC on Minimal CentOS 7\n\n","slug":"ml-jieba-opencc","date":"2024-11-18T05:40:13.000Z","categories_index":"NLP","tags_index":"NLP,Jieba,Linux,ML,OpenCC,CentOS","author_index":"Kevin"},{"id":"882d31fc168f9dee83d771cd41dd9d18","title":"Ubuntu/Python 结巴分词 + Word2Vec利用维基百科训练词向量","content":"Ubuntu&#x2F;Python 结巴分词 + Word2Vec利用维基百科训练词向量结巴分词是一个跨语言的中文分词器，整体效果还算不错，功能也够用，这里直接用Python了，其他主流语言版本均有提供。\nWord2Vec，起源于谷歌的一个项目，在我刚开始接触的时候就关注到了他的神奇，大致是通过深度神经网络把词映射到N维空间，处理成向量之后我们终于可以在自然语言处理上方便的使用它进行一些后续处理。（具体的方法忘了）\nPython的gensim库中有word2vec包，我们使用这个就可以了，接下来我们就对维基百科进行处理，作为训练集去训练。（包地址：http://radimrehurek.com/gensim/models/word2vec.html）\n本文参考：\n中英文维基百科语料上的word2vec实验\nUbuntu&#x2F;Python 结巴分词 + Word2Vec利用维基百科训练词向量\n安装\n依赖库是Numpy和SciPy，在Scipy的说明里有：\n1pip install numpy scipy matplotlib ipython ipython-notebook pandas sympy nose\n安装期间如果遇到问题，可以使用：\n1yum install gcc g++\n这样安装完成之后，继续\n1pip install gensim\n下载不动，换源再试，依旧安装失败，似乎是在编译时出现了问题，具体查了一下也没有查出什么问题，只是有人说手动安装成功了，那么我就试试手动安装吧。\n手动安装就是在pip官网上把对应的包下载下来，然后sudo python setup.py install，结果似乎没什么问题。总算是安装上了。\n打开python终端尝试import也能用，换言之我们总算可以用了。\n处理\n使用维基百科的数据很方便，一是Wiki给我们提供了现成的语料库（听说是实时更新的），虽然中文体积不大，但比起自己爬来方便了不少。\n如果使用英文那就更棒了，非常适合作为语料库。\n当然只是说在通用的情况下，在专业词汇上，经过测试效果比较一般（考虑到专业词库有专业wiki，以及中文词条本身也不太多）。\n首先，我们把Wiki处理成Text格式待处理的文本，这一步在本文参考中有现成的代码。\n12345678910111213141516171819202122232425262728293031#!/usr/bin/env python# -*- coding: utf-8 -*-import loggingimport os.pathimport sysfrom gensim.corpora import WikiCorpusif __name__==&#x27;__main__&#x27;:    program = os.path.basename(sys.argv[0])    logger = logging.getLogger(program)    logging.basicConfig(format=&#x27;%(asctime)s: %(levelname)s: %(message)s&#x27;)    logging.root.setLevel(logging.INFO)    console = logging.StreamHandler()    console.setLevel(logging.INFO)    logging.getLogger(&#x27;&#x27;).addHandler(console)    logger.info(&quot;running %s&quot; % &#x27; &#x27;.join(sys.argv))    #check and process input arguments    if len(sys.argv) &lt; 3:        print globals()[&#x27;__doc__&#x27;] % locals()        sys.exit(1)    inp, outp = sys.argv[1:3]    space = &quot; &quot;    i = 0    output = open(outp, &#x27;w&#x27;)    wiki = WikiCorpus(inp, lemmatize=False, dictionary=&#123;&#125;)    for text in wiki.get_texts():        output.write(space.join(text) + &quot;\\n&quot;)        i = i + 1        if (i % 10000 == 0):            logger.info(&quot;Saved &quot; + str(i) + &quot; articles&quot;)    output.close()    logger.info(&quot;Finished Saved &quot; + str(i) + &quot; articles&quot;)\nlogger比print更规范，过去没有用过相关的，不太会用，其实用起来还是蛮方便的，这里暂时就先不介绍了。\nWiki的处理函数在gensim库中有，通过处理我们可以发现，最终效果是变成一行一篇文章并且空格分隔一些关键词，去掉了标点符号。\n执行：\n1python process_wiki.py zhwiki-latest-pages-articles.xml.bz2 wiki.zh.text\n等待处理结果，比较漫长，基本上接下来你可以随便做点什么了。\n处理完成之后我们会发现，简体和繁体并不统一，所以我们需要用opencc进行简繁体的转换，这里不得不说BYVoid是个非常牛逼的同学。这个被官方收录了，我们可以直接用\n1yum install opencc\n来安装，github开源：https://github.com/BYVoid/OpenCC\n如果安装不成功，参考我的另一篇文章 Compile and Install OpenCC on Minimal CentOS 7\n然后执行：\n1opencc -i wiki.zh.text -o wiki.zh.text.jian -c zht2zhs.ini\n\n得到简体中文的版本，这一步的速度还可以。\n分词\n下一步，分词，原文中用的似乎有些复杂，结巴分词的效果其实已经不错了，而且很好用，这里就用结巴分词处理一下。本身而言结巴分词是不去掉标点的，但是由于上一步帮我们去掉了，所以这里我们比较省力（不然的话原本准备遍历去掉，根据词性标注标点为x）。\n我的Python还是不太6，所以写的代码比较难看OTZ，不过效果是实现了，处理起来比较慢，我觉得readlines里的参数可以更多一点。\n这里下面处理完了之后用map处理，拼接list并且使用utf-8编码，此外，保证一行一个文章，空格分隔（这是后续处理函数的规定）。\n这里分词没开多线程，不过后来发现瓶颈似乎在读取的IO上。\n123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/env python#-*- coding:utf-8 -*-import jiebaimport jieba.analyseimport jieba.posseg as psegdef cut_words(sentence):    #print sentence    return &quot; &quot;.join(jieba.cut(sentence)).encode(&#x27;utf-8&#x27;) #如果writelines报错，删除.encode(&#x27;utf-8&#x27;)f = open(&quot;wiki.zh.text.jian&quot;)target = open(&quot;wiki.zh.text.jian.seg&quot;, &#x27;a+&#x27;)print(&#x27;open files&#x27;)line = f.readlines(100000)while line:    curr = []    for oneline in line:        #print(oneline)        curr.append(oneline)    &#x27;&#x27;&#x27;    seg_list = jieba.cut_for_search(s)    words = pseg.cut(s)    for word, flag in words:        if flag != &#x27;x&#x27;:            print(word)    for x, w in jieba.analyse.extract_tags(s, withWeight=True):        print(&#x27;%s %s&#x27; % (x, w))    &#x27;&#x27;&#x27;    after_cut = map(cut_words, curr)    # print lin,    #for words in after_cut:        #print words    target.writelines(after_cut)    print(&#x27;saved 100000 articles&#x27;)    line = f.readlines(100000)f.close()target.close()print(&quot;end&quot;)\n\n训练\n最后就能愉快的训练了，训练函数还是参考了原文：\n1234567891011121314151617181920212223#!/usr/bin/env python#-*- coding:utf-8 -*-import loggingimport os.pathimport sysimport multiprocessingfrom gensim.corpora import WikiCorpusfrom gensim.models import Word2Vecfrom gensim.models.word2vec import LineSentenceif __name__ == &#x27;__main__&#x27;:    program = os.path.basename(sys.argv[0])    logger = logging.getLogger(program)    logging.basicConfig(format=&#x27;%(asctime)s: %(levelname)s: %(message)s&#x27;)    logging.root.setLevel(level=logging.INFO)    logger.info(&quot;running %s&quot; % &#x27; &#x27;.join(sys.argv))    # check and process input arguments    if len(sys.argv) &lt; 4:        print globals()[&#x27;__doc__&#x27;] % locals()        sys.exit(1)    inp, outp1, outp2 = sys.argv[1:4]    model = Word2Vec(LineSentence(inp), size=400, window=5, min_count=5, workers=multiprocessing.cpu_count())    model.save(outp1)    model.save_word2vec_format(outp2, binary=False)\n这里用了一个个LineSentence函数，官方文档：http://radimrehurek.com/gensim/models/word2vec.html\n文档这么说：\n\n\n\n\n\n\n\n\n\nSimple format: one sentence &#x3D; one line; words already preprocessed and separated by whitespace.简单的格式：一句话 &#x3D; 一行，预处理过并且用空白符分隔。\n这里我们一篇文章等于一行。\n执行训练：\n1python train_word2vec_model.py wiki.zh.text.jian.seg wiki.zh.text.model wiki.zh.text.vector\n训练速度也还可以。\n之后我们就可以根据这个进行Word2Vec相关操作了：\n1234567891011121314151617181920212223242526272829303132333435import gensimmodel = gensim.models.Word2Vec.load(&quot;wiki.zh.text.model&quot;)#model.most_similar(u&quot;足球&quot;)&quot;&quot;&quot;[(u&#x27;\\u8054\\u8d5b&#x27;, 0.6553816199302673), (u&#x27;\\u7532\\u7ea7&#x27;, 0.6530429720878601), (u&#x27;\\u7bee\\u7403&#x27;, 0.5967546701431274), (u&#x27;\\u4ff1\\u4e50\\u90e8&#x27;, 0.5872289538383484), (u&#x27;\\u4e59\\u7ea7&#x27;, 0.5840631723403931), (u&#x27;\\u8db3\\u7403\\u961f&#x27;, 0.5560152530670166), (u&#x27;\\u4e9a\\u8db3\\u8054&#x27;, 0.5308005809783936), (u&#x27;allsvenskan&#x27;, 0.5249762535095215), (u&#x27;\\u4ee3\\u8868\\u961f&#x27;, 0.5214947462081909), (u&#x27;\\u7532\\u7ec4&#x27;, 0.5177896022796631)]&quot;&quot;&quot;result = model.most_similar(u&quot;足球&quot;)for e in result:    print e[0], e[1]&quot;&quot;&quot;联赛 0.65538161993甲级 0.653042972088篮球 0.596754670143俱乐部 0.587228953838乙级 0.58406317234足球队 0.556015253067亚足联 0.530800580978allsvenskan 0.52497625351代表队 0.521494746208甲组 0.51778960228&quot;&quot;&quot;\n搞完这一波，一天也就差不多过去了……至于训练效果，取决于语料库以及我们的分词效果两点，可以针对这两点进行处理。\n附：Notebook版12345678910111213141516171819202122232425262728293031323334import loggingimport os.pathimport sysfrom gensim.corpora import WikiCorpus# if __name__==&#x27;__main__&#x27;:sys.argv[0] = &quot;process_wiki&quot;sys.argv[1] = &quot;/root/zhwiki-latest-pages-articles.xml.bz2&quot;sys.argv[2] = &quot;wiki.zh.text&quot;program = os.path.basename(sys.argv[0])logger = logging.getLogger(program)logging.basicConfig(format=&#x27;%(asctime)s: %(levelname)s: %(message)s&#x27;)logging.root.setLevel(logging.INFO)console = logging.StreamHandler()console.setLevel(logging.INFO)logging.getLogger(&#x27;&#x27;).addHandler(console)logger.info(&quot;running %s&quot; % &#x27; &#x27;.join(sys.argv))#check and process input argumentsif len(sys.argv) &lt; 3:    print(globals()[&#x27;__doc__&#x27;] % locals())    sys.exit(1)inp, outp = sys.argv[1:3]space = &quot; &quot;i = 0output = open(outp, &#x27;w&#x27;)wiki = WikiCorpus(inp, lemmatize=False, dictionary=&#123;&#125;)for text in wiki.get_texts():    output.write(space.join(text) + &quot;\\n&quot;)    i = i + 1    if (i % 10000 == 0):        logger.info(&quot;Saved &quot; + str(i) + &quot; articles&quot;)output.close()logger.info(&quot;Finished Saved &quot; + str(i) + &quot; articles&quot;)\n123456789101112131415161718192021222324252627282930313233343536import jiebaimport jieba.analyseimport jieba.posseg as psegimport jsondef cut_words(sentence):    #print sentence    return &quot; &quot;.join(jieba.cut(sentence))f = open(&quot;/root/wiki.zh.text.jian&quot;)target = open(&quot;/root/wiki.zh.text.jian.seg&quot;, &#x27;a+&#x27;)print(&#x27;open files&#x27;)line = f.readlines(100000)while line:    curr = []    for oneline in line:        #print(oneline)        curr.append(oneline)    &#x27;&#x27;&#x27;    seg_list = jieba.cut_for_search(s)    words = pseg.cut(s)    for word, flag in words:        if flag != &#x27;x&#x27;:            print(word)    for x, w in jieba.analyse.extract_tags(s, withWeight=True):        print(&#x27;%s %s&#x27; % (x, w))    &#x27;&#x27;&#x27;    after_cut = map(cut_words, curr)    # print lin,#     for words in after_cut:#         print(words)#     print(json.dumps(after_cut))    target.writelines(after_cut)    print(&#x27;saved 100000 articles&#x27;)    line = f.readlines(100000)f.close()target.close()print(&quot;end&quot;)\n123456789101112131415161718192021222324252627import loggingimport os.pathimport sysimport multiprocessingfrom gensim.corpora import WikiCorpusfrom gensim.models import Word2Vecfrom gensim.models.word2vec import LineSentence# if __name__ == &#x27;__main__&#x27;:sys.argv[0] = &quot;train_word2vec_model.py&quot;inp = &quot;/root/wiki.zh.text.jian.seg&quot;outp1 = &quot;/root/wiki.zh.text.model&quot;outp2 = &quot;/root/wiki.zh.text.vector&quot;program = os.path.basename(sys.argv[0])logger = logging.getLogger(program)logging.basicConfig(format=&#x27;%(asctime)s: %(levelname)s: %(message)s&#x27;)logging.root.setLevel(level=logging.INFO)logger.info(&quot;running %s&quot; % &#x27; &#x27;.join(sys.argv))# check and process input arguments# if len(sys.argv) &lt; 4:#     print(globals()[&#x27;__doc__&#x27;] % locals())#     sys.exit(1)# inp, outp1, outp2 = sys.argv[1:4]model = Word2Vec(LineSentence(inp), size=400, window=5, min_count=5, workers=multiprocessing.cpu_count())model.save(outp1)model.save_word2vec_format(outp2, binary=False)\n12345678910import gensimmodel = gensim.models.Word2Vec.load(&quot;/root/wiki.zh.text.model&quot;)# print(model)# model.most_similar(u&quot;男人&quot;)result = model.most_similar(u&quot;男人&quot;)for e in result:    print(e[0], e[1])\n\n扩展阅读：\n深度学习word2vec笔记之基础篇\nDeep Learning实战之word2vec\n","slug":"jieba-word2vec","date":"2024-11-18T05:40:13.000Z","categories_index":"NLP","tags_index":"NLP,Jieba,Word2Vec,Linux,Ubuntu,Python","author_index":"Kevin"},{"id":"fa8de5b59170093e2dea98ffe77b6754","title":"关于`SparkLivy`和`ZeppelinNotebook`访问`HDFS`时的多用户权限控制","content":"关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制SparkLivy在Yarn上运行应用时，默认使用的用户是Livy。\nZeppelinNotebook在使用%Spark等非%Livy的Interpreter时，使用的用户是Zeppelin。\nLivy和Zeppelin用户默认在HDFS上的用户组是hdfs，默认具有HDFS上所有目录及文件的r-x权限。\n这样就会存在以下问题。\n问题一：多用户描述所有用户在使用SparkLivy或者使用Zeppelin时都使用的是同一个用户（Livy或Zeppelin），这样就无法控制用户应用（代码级别）对HDFS的访问权限，所有用户都使用的是Livy或Zeppelin的用户权限。\n解决方案SparkLivy\n在创建batch或者session的时候添加proxyUser参数，指定当前用户。详见：SparkLivy REST API\nZeppelinNotebook\n\n\n\n\n\n\n\n\n\n关于ZeppelinNotebook自身的多用户配置，请阅读本人的另一篇文章配置Zeppelin使用Apache Shiro进行鉴权（多用户登录）。\n當把interpreter設定為isolated的時候某方面的確達到了多使用者共同使用Zeppelin的環境(详细Zeppelin配置)，但是那只限於Zeppelin這個平台本身，後來遇到了Zeppelin所有使用者在YARN裏面會用相同user啟動的狀況，這樣一來對於使用者的追蹤變的困難。\n後來找了一下Zeppelin的討論目前對於使用者權限區隔的問題，Zeppelin採用Livy這個Spark Proxy當作解決方案，再搭配Zeppelin內建的Livy Interpreter，能夠對Zeppelin的使用者做到區隔的動作。(转自：Zeppelin 支援多用戶-Livy Server篇)\n\n\n\n\n\n\n\n\n\n目前仍存在一个问题，在作者qwemicheal的文章Zeppelin 和livy结合实现代理用户中如何代理ldap邮箱用户中提到“使用zeppelin+livy的方式实现用户代理和后台权限控制．优点在于livy支持cluster模式 并seesion 客户端一段时间(默认６０分钟)不活动会自动中止spark任务”。但是当多用户同时使用时，仍然会出现Spark集群无资源可用的情况。那么就需要将session客户端的终止时间缩短。本人经过多次试验终究没有设置成功，最终在Web项目中添加轮询线程，调用SparkLivy的API结束掉状态为Idle的session，以释放Spark集群资源。\n总结经过以上方法，解决了多用户的用户隔离问题，以及Zeppelin资源占用问题。但轮询线程仍然会消耗系统资源，未能找到最优解决方案。希望有想法的道友能指点一二。\n问题二：HDFS用户权限问题一结果了多用户的问题，使Web项目的用户可以和Hadoop生态关联，但仍未控制用户在Hadoop平台上的权限（本文仅介绍关于HDFS的权限控制）。\n解决方案启用HDFS的ACLs\n在hdfs-site.xml文件中添加配置项，以在HDFS上启用ACL：\n1234&lt;property&gt;  &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;\n\n将此属性设置为“true”以启用对ACL的支持。ACL默认是禁用的。当禁用ACL时，NameNode拒绝所有对ACL的设置。\n使用CLI命令创建和列出ACLs\n两个新的子命令被添加到FsShell：setfacl和getfacl。这些命令是在相同的Linux shell命令之后建模的，但实现的标志较少。如果需要，可以稍后添加对其他标志的支持。\n\nsetfacl\n\n设置文件和目录的ACL。\n例：\n-setfacl [-bkR] {-m | -x}  &lt;path&gt;\n-setfacl –set  &lt;path&gt;\n选项：\n表6.1. ACL选项\n\n\n\n选项\n描述\n\n\n\n-b\n删除所有条目，但保留基本ACL条目。“用户”，“组”和“其他”的条目保留为与“权限位”兼容。\n\n\n-k\n删除默认ACL。\n\n\n-R\n将操作递归地应用于所有文件和目录。\n\n\n-m\n修改ACL。新的条目被添加到ACL中，并保留现有的条目。\n\n\n-x\n删除指定的ACL条目。所有其他ACL条目都保留。\n\n\n–set\n完全替换ACL并放弃所有现有的条目。acl_spec必须包含User，Group和Others的条目，以便与Permission Bits兼容。\n\n\n\n逗号分隔的ACL条目列表。\n\n\n&lt;path&gt;\n要修改的文件或目录的路径。\n\n\n例子：\n1234567hdfs dfs -setfacl -m user:hadoop:rw- /filehdfs dfs -setfacl -x user:hadoop /filehdfs dfs -setfacl -b /filehdfs dfs -setfacl -k /dirhdfs dfs -setfacl --set user::rw-,user:hadoop:rw-,group::r--,other::r-- /filehdfs dfs -setfacl -R -m user:hadoop:r-x /dirhdfs dfs -setfacl -m default:user:hadoop:r-x /dir\n\n退出代码：\n成功返回0，错误返回非零。\n\ngetfacl\n\n显示文件和目录的ACL。如果某个目录具有默认ACL，则getfacl还会显示默认ACL。\n用法：\n1-getfacl [-R] &lt;path&gt;\n\n选项：​表6.2. getfacl选项\n\n\n\n选项\n描述\n\n\n\n-R\n以递归方式列出所有文件和目录的ACL。\n\n\n&lt;path&gt;\n要列出的文件或目录的路径。\n\n\n例子：\n12hdfs dfs -getfacl /filehdfs dfs -getfacl -R /dir\n\n退出代码：\n成功返回0，错误返回非零。\n\n\n\n\n\n\n\n\n\n为每个用户指定需要访问的目录或者文件，指定文件的ACL时，需要指定所有父级目录的ACL！！！\n","slug":"sparklivy-zeppelin-hdfs-mutil-user-auth","date":"2017-12-09T09:29:08.000Z","categories_index":"Big Data","tags_index":"Zeppelin,Hadoop,SparkLivy,Zeppelin Notebook,HDFS,Mutil User,Auth","author_index":"Kevin"},{"id":"f600e8de35fac4a36aec15d10c646ff1","title":"Hadoop生态部分组件介绍","content":"Apache Hadoop\n\n\n\n\n\n\n\n\nApache Hadoop是一款支持数据密集型分布式应用程序并以Apache 2.0许可协议发布的开源软件框架。它支持在商品硬件构建的大型集群上运行的应用程序。Hadoop是根据谷歌公司发表的MapReduce和Google文件系统的论文自行实现而成。所有的Hadoop模块都有一个基本假设，即硬件故障是常见情况，应该由框架自动处理。Hadoop框架透明地为应用提供可靠性和数据移动。它实现了名为MapReduce的编程范式：应用程序被分区成许多小部分，而每个部分都能在集群中的任意节点上运行或重新运行。此外，Hadoop还提供了分布式文件系统，用以存储所有计算节点的数据，这为整个集群带来了非常高的带宽。MapReduce和分布式文件系统的设计，使得整个框架能够自动处理节点故障。它使应用程序与成千上万的独立计算的电脑和PB级的数据连接起来。现在普遍认为整个Apache Hadoop“平台”包括Hadoop内核、MapReduce、Hadoop分布式文件系统（HDFS）以及一些相关项目，有Apache Hive和Apache HBase等等。\nApache Spark\n\n\n\n\n\n\n\n\nApache Spark是一个开源集群运算框架，最初是由加州大学柏克莱分校AMPLab所开发。相对于Hadoop的MapReduce会在运行完工作后将中介数据存放到磁盘中，Spark使用了内存内运算技术，能在数据尚未写入硬盘时即在内存内分析运算。Spark在内存内运行程序的运算速度能做到比Hadoop MapReduce的运算速度快上100倍，即便是运行程序于硬盘时，Spark也能快上10倍速度。Spark允许用户将数据加载至集群内存，并多次对其进行查询，非常适合用于机器学习算法。使用Spark需要搭配集群管理员和分布式存储系统。Spark支持独立模式（本地Spark集群）、Hadoop YARN或Apache Mesos的集群管理。 在分布式存储方面，Spark可以和HDFS、 Cassandra 、OpenStack Swift和Amazon S3等接口搭载。 Spark也支持伪分布式（pseudo-distributed）本地模式，不过通常只用于开发或测试时以本机文件系统取代分布式存储系统。在这样的情况下，Spark仅在一台机器上使用每个CPU核心运行程序。在2014年有超过465位贡献家投入Spark开发，让其成为Apache软件基金会以及大数据众多开源项目中最为活跃的项目。\nApache Livy\n\n\n\n\n\n\n\n\nApache Livy是一种服务，可以通过REST接口轻松与Spark群集进行交互。通过简单的REST接口或RPC客户端库，可轻松提交Spark作业或Spark代码片段，同步或异步结果检索以及Spark上下文管理。Apache Livy还简化了Spark和应用程序服务器之间的交互，从而使Spark能够用于交互式Web &#x2F;移动应用程序。\nApache Zeppelin\n\n\n\n\n\n\n\n\nApache Zeppelin  是一个让交互式数据分析变得可行的基于网页的开源框架。Zeppelin提供了数据分析、数据可视化等功能。Zeppelin 是一个提供交互数据分析且基于Web的笔记本。方便你做出可数据驱动的、可交互且可协作的精美文档，并且支持多种语言，包括 Scala(使用 Apache Spark)、Python(Apache Spark)、SparkSQL、 Hive、 Markdown、Shell等等。\nApache Shiro\n\n\n\n\n\n\n\n\nApache Shiro（读作“sheeroh”，即日语“城”）是一个开源安全框架，提供身份验证、授权、密码学和会话管理。Shiro框架直观、易用，同时也能提供健壮的安全性。\n","slug":"hadoop-components","date":"2017-10-09T07:51:17.000Z","categories_index":"Big Data","tags_index":"Zeppelin,Shiro,Hadoop,Spark,Livy","author_index":"Kevin"},{"id":"0d796f28558c1909e22d612dcdac7f4d","title":"Hadoop Notes","content":"Hadoop NotesNote1问题描述Yarn不能同时运行多个application\n问题分析经观察ResourceManager UI\n\n\n与执行命令\n\n\n\n\n\n\n\n\n\nHADOOP_USER_NAME&#x3D;hdfs .&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster --driver-memory 2g --executor-memory 2g –executor-cores 1 –queue default examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 10\n发现单个application申请的资源（内存、CPU）超过单个node上最大资源一半，导致没有足够资源供其余application运行，所以多个application同时运行时，后提交的application会等待有足够的资源时再运行。\n解决方法在Ambari中设置YARN的Memory和CPU\n\n\n调整执行命令中的内存大小，使之不超过YARN配置中设置的大小，合理安排内存，Memory for Node / Application Memory = Num of Application\nNote2问题描述HST Agent 无法启动\nhst-agent.log\n123INFO 2017-09-30 11:55:06,287 security.py:178 - Server certificate not exists, downloadingINFO 2017-09-30 11:55:06,287 security.py:191 - Downloading server cert from https://slave2:9440/cert/ca/ERROR 2017-09-30 11:55:06,345 ServerAPI.py:84 - GET https://slave2:9441/api/v1/hst_agents/slave2 failed. (SSLError(1, u&#x27;[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:579)&#x27;),)\n\n原因未注册并配置SmartSense Account\n","slug":"hadoop-notes","date":"2017-09-30T04:17:23.000Z","categories_index":"Big Data","tags_index":"Hadoop","author_index":"Kevin"},{"id":"98e85a349358aba091f9064f5f1ca497","title":"配置Zeppelin使用Apache Shiro进行鉴权（多用户登录）","content":"配置Zeppelin使用Apache Shiro进行鉴权（多用户登录）本人使用的Ambari搭建的Hadoop集群，Zeppelin也是Ambari管理的集群中的一部分。\nAmbari安装集群方法见本人的另外一篇文章Ambari安装Hadoop集群教程\nZeppelin有ini、Active Directory、LDAP、PAM、ZeppelinHub、Apache Shiro Realms（JndiLdapRealm、JdbcRealm or create our own）六种鉴权方式具体介绍见Apache Shiro authentication for Apache Zeppelin\nZeppelinHub 经初步测试，貌似因ZeppelinHub官网域名更换，导致无法使用\n本文仅介绍LADP、JdbcRealm两种鉴权方式\nladp与jdbc对比\n使用ldapRealm需要安装Knox，然后启动Demo LDAP服务，用户需在配置文件配置，添加用户需重启服务。\n使用jdbcRealm需安装mysql数据库，可动态添加用户。\n\n如需动态添加用户，推荐使用jdbcRealm。\njdbcRealm使用教程创建数据库和表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647DROP DATABASE IF EXISTS shiro;CREATE DATABASE shiro\tCHARACTER SET utf8\tCOLLATE utf8_general_ci;DROP TABLE IF EXISTS roles_permissions;CREATE TABLE roles_permissions (  id BIGINT(20) NOT NULL AUTO_INCREMENT,  role_name VARCHAR(100) DEFAULT NULL,  permission VARCHAR(100) DEFAULT NULL,  PRIMARY KEY (id),  UNIQUE INDEX idx_roles_permissions (role_name, permission))ENGINE = INNODBAUTO_INCREMENT = 2AVG_ROW_LENGTH = 16384CHARACTER SET utf8COLLATE utf8_general_ci;DROP TABLE IF EXISTS user_roles;CREATE TABLE user_roles (  id BIGINT(20) NOT NULL AUTO_INCREMENT,  username VARCHAR(100) DEFAULT NULL,  role_name VARCHAR(100) DEFAULT NULL,  PRIMARY KEY (id),  UNIQUE INDEX idx_user_roles (username, role_name))ENGINE = INNODBAUTO_INCREMENT = 2AVG_ROW_LENGTH = 16384CHARACTER SET utf8COLLATE utf8_general_ci;DROP TABLE IF EXISTS users;CREATE TABLE users (  id BIGINT(20) NOT NULL AUTO_INCREMENT,  username VARCHAR(100) DEFAULT NULL,  password VARCHAR(100) DEFAULT NULL,  password_salt VARCHAR(100) DEFAULT NULL,  PRIMARY KEY (id),  UNIQUE INDEX idx_users_username (username))ENGINE = INNODBAUTO_INCREMENT = 3AVG_ROW_LENGTH = 8192CHARACTER SET utf8COLLATE utf8_general_ci;\n\nZeppelin Shiro.ini 配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374[users]# List of users with their password allowed to access Zeppelin.# To use a different strategy (LDAP / Database / ...) check the shiro doc at http://shiro.apache.org/configuration.html#Configuration-INISectionsadmin = admin, adminuser1 = user1, role1, role2user2 = user2, role3user3 = user3, role2# Sample LDAP configuration, for user Authentication, currently tested for single Realm[main]#使用ldap或jdbc其中一个###########################ldap start############################ ldapRealm = org.apache.zeppelin.realm.LdapGroupRealm# ldapRealm.contextFactory.environment[ldap.searchBase] = dc=hadoop,dc=apache,dc=org# ldapRealm.contextFactory.url = ldap://slave1:33389# ldapRealm.userDnTemplate = uid=&#123;0&#125;,ou=people,dc=hadoop,dc=apache,dc=org# ldapRealm.contextFactory.authenticationMechanism = SIMPLE# ldapRealm.contextFactory.systemUsername = uid=sam,ou=people,dc=hadoop,dc=apache,dc=org# ldapRealm.contextFactory.systemPassword = sam-password###########################ldap end######################################################jdbc start###########################jdbcRealm=org.apache.shiro.realm.jdbc.JdbcRealm# jdbcRealm.authenticationQuery = SELECT password from users where username = ?# jdbcRealm.userRolesQuery = select role from userroles where userID = (select id FROM user WHERE username = ?)ds = com.mysql.jdbc.jdbc2.optional.MysqlDataSourceds.serverName = rm-xxxxxxxxxxxxx.mysql.rds.aliyuncs.comds.user = userds.password = passwordds.databaseName = dbjdbcRealm.dataSource= $dspasswordMatcher = org.apache.shiro.authc.credential.Sha256CredentialsMatcherjdbcRealm.credentialsMatcher = $passwordMatcher###########################jdbc end############################## A sample PAM configuration#pamRealm=org.apache.zeppelin.realm.PamRealm#pamRealm.service=sshdsessionManager = org.apache.shiro.web.session.mgt.DefaultWebSessionManager### If caching of user is required then uncomment below linescacheManager = org.apache.shiro.cache.MemoryConstrainedCacheManagersecurityManager.cacheManager = $cacheManagersecurityManager.sessionManager = $sessionManager# 86,400,000 milliseconds = 24 hoursecurityManager.sessionManager.globalSessionTimeout = 86400000shiro.loginUrl = /api/login[roles]role1 = *role2 = *role3 = *admin = *[urls]# This section is used for url-based security.# You can secure interpreter, configuration and credential information by urls. Comment or uncomment the below urls that you want to hide.# anon means the access is anonymous.# authc means Form based Auth Security# To enfore security, comment the line below and uncomment the next one/api/version = anon#/api/interpreter/** = authc, roles[admin]#/api/configurations/** = authc, roles[admin]#/api/credential/** = authc, roles[admin]#/** = anon/** = authc\n\n添加数据密码需要使用SHA-256方式加密后存入数据库\n重启ZeppelinKO！\nldapRealm使用教程\n安装Knox，启动Demo LDAP服务\n\n修改Shiro.ini配置文件，添加上边ldap中的内容，重启Zeppelin\n其中 ldapRealm.contextFactory.url &#x3D; ldap:&#x2F;&#x2F;slave1:33389的slave1改为Knox所在服务器的ip\n\n\n具体教程会在Kevin’s Blog(www.kevinsui.com)中更新。\n在Zeppelin中，用户登录后，在每个notebook中设置访问权限。","slug":"ambari-zeppelin-shiro","date":"2017-09-27T10:51:57.000Z","categories_index":"Big Data","tags_index":"Ambari,Zeppelin,Shiro,Hadoop","author_index":"Kevin"},{"id":"26ca6bb559630836911bd4e42d633e9b","title":"Ambari安装Hadoop集群教程","content":"Ambari安装Hadoop集群教程集群环境：阿里云服务器系统：Centos7\nLinux master 3.10.0-514.16.1.el7.x86_64 #1 SMP Wed Apr 12 15:04:24 UTC 2017 x86_64 x86_64 x86_64 GNU&#x2F;Linux\n配置：master * 1 -&gt; CPU : 4 core RAM : 16G OS_DISK : 40G DATA_DISK : 1T\nslave * 2 -&gt; CPU : 4 core RAM : 8G OS_DISK : 40G DATA_DISK : 1T\n版本AmbariAmbari-2.5.2.0-centos7\nHDPHDP-2.6.1.0-centos7\nHDP-UTILSHDP-UTILS-1.1.0.21-centos7\n准备环境pyenv installation使用pyenv创建虚拟python环境，可用来装anaconda环境，供pyspark程序使用\n1234567891011121314151617181920212223242526272829#安装依赖yum install readline readline-devel readline-static -yyum install openssl openssl-devel openssl-static -yyum install sqlite-devel -yyum install bzip2-devel bzip2-libs -yyum install git-core bzip2 -y#下载并执行自动安装脚本curl -L https://raw.github.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash#添加下面代码到~/.bashrcexport PATH=&quot;/root/.pyenv/bin:$PATH&quot;eval &quot;$(pyenv init -)&quot;eval &quot;$(pyenv virtualenv-init -)&quot;#下载python安装包wget http://mirrors.sohu.com/python/3.6.2/Python-3.6.2.tar.xz#创建pyenv下载缓存目录mkdir ~/.pyenv/cache#将已下载的python安装包复制到pyenv下载缓存目录cp Python-3.6.2.tar.xz ~/.pyenv/cache#pyenv安装python，如果cache目录有对应版本安装包，就使用其进行安装，否则会在线下载安装包（墙内慢到死）pyenv install 3.6.2#设置全局系统python版本（hadoop生态相关组件可能不支持python3）#pyenv global 3.6.2\n\nnginx installation使用nginx作为ambari离线仓库，进行ambari、HDP、HDP-Utils安装\n12345678910111213#安装nginxyum install nginx -y#编辑nginx配置文件vim /etc/nginx/nginx.conf#修改80端口的server中的root目录为离线安装包的目录root  /mnt/ambari;#测试nginx配置文件是否正确nginx -t#启动nginxnginx\n\n配置集群免密登录12345678910111213#创建ssh密钥对ssh-keygen#输出公钥到authorized_keys文件cat id_rsa.pub &gt;&gt; authorized_keys#在集群中所有的服务器中创建.ssh目录mkdir ~/.ssh#复制authorized_keys文件到集群所有机器上的.ssh目录中#修改对应目录及文件权限chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys\n\n配置DNS12345vim /etc/hosts#在文件中添加集群所有机器的IP和FQDN，例如：10.30.xxx.xx1 master10.31.xxx.xx2 slave110.31.xxx.xx3 slave2\n\nntp installation12yum install -y ntpchkconfig ntpd on\n\nset hostname123456789hostname master#hostname slave1#hostname slave2vim /etc/sysconfig/network#添加/修改HOSTNAMEHOSTNAME=master#HOSTNAME=slave1#HOSTNAME=slave2\n\n关闭防火墙（CENTOS 7）12chkconfig firewalld offservice firewalld stop\n\n禁用selinux123456#查看selinux状态sestatus#禁用selinuxvim /etc/yum/pluginconf.d/refresh-packagekit.confsetenforce 0\n\n检查umask值12345#检查umask值umask#设置umask值echo umask 0022 &gt;&gt; /etc/profile\n\n开启PackageKit12/etc/yum/pluginconf.d/refresh-packagekit.confenabled=0\n\n\n安装ambari添加本地仓库Ambari Base URL\n12http://&lt;web.server&gt;/Ambari-2.5.1.0/&lt;OS&gt;http://master/ambari/centos7\nHDF Base URL\n123http://&lt;web.server&gt;/hdf/HDF/&lt;OS&gt;/3.x/updates/&lt;latest.version&gt;http://&lt;web.server&gt;/hdp/HDP/&lt;OS&gt;/2.x/updates/&lt;latest.version&gt;http://master/HDP/centos7\nHDP-UTILS Base URL\n12http://&lt;web.server&gt;/hdp/HDP-UTILS-&lt;version&gt;/repos/&lt;OS&gt;http://master/HDP-UTILS-1.1.0.21\n\n创建ambari.repo文件\n123456789vim /etc/yum.repos.d/ambari.repo[Updates-Ambari-2.5.2.0]name=Ambari-2.5.2.0-Updatesbaseurl=http://10.30.xxx.xx1/ambari/centos7gpgcheck=1gpgkey=http://10.30.xxx.xx1/ambari/centos7/RPM-GPG-KEY/RPM-GPG-KEY-Jenkinsenabled=1priority=1\n\nOptional: If you have multiple repositories configured in your environment, deploy the following plug-in on all the nodes in your cluster.\na.\tInstall the plug-in.\n1yum install yum-plugin-priorities\n\nb.\tEdit the &#x2F;etc&#x2F;yum&#x2F;pluginconf.d&#x2F;priorities.conf file to add the following:\n123[main]enabled=1gpgcheck=0\n\n下载离线安装包12345678910#ambari离线安装包wget http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.5.1.0/ambari-2.5.1.0-centos7.tar.gz#HDP安装包版本信息wget http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.1.0/HDP-2.6.1.0-129.xml#HDP离线安装包wget http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.1.0/HDP-2.6.1.0-centos7-rpm.tar.gz#HDP-UTILS离线安装包wget http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7/HDP-UTILS-1.1.0.21-centos7.tar.gz\n\n安装ambari-server1yum install ambari-server -y\n\n配置ambari-server1ambari-server setup\n如果jdk安装过慢，先下载好jdk安装包再安装ambari-server\n123456789101112#ambari原始jdk下载地址#wget http://public-repo-1.hortonworks.com/ARTIFACTS/jdk-8u112-linux-x64.tar.gz -O /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz#oracle官网jdk下载地址#wget --no-cookies \\#--no-check-certificate \\#--header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; \\#&quot;http://public-repo-1.hortonworks.com/ARTIFACTS/jdk-8u112-linux-x64.tar.gz&quot; \\#-O /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz#国内jdk镜像下载地址[推荐]wget http://mirrors.linuxeye.com/jdk/jdk-8u112-linux-x64.tar.gz -O /var/lib/ambari-server/resources/jdk-8u112-linux-x64.tar.gz\n\n启动ambari-server1ambari-server start\n\nambari访问地址http://master:8080\n建立集群add versionhttp://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.1.0/HDP-2.6.1.0-129.xml\nadd clustercluster FQDNs\n123masterslave1slave2\n\n添加私钥文件id_rsa\nError1123# slave1: parent directory /usr/hdp/current/hadoop-client/conf doesn&#x27;t exist创建对应目录\n\n\nNote11234567# read file from hdfs urlhdfs://+path# example: hdfs:///tmp/ProjectFile/*.dat# note: // is protocol, / is root\n","slug":"ambari-install","date":"2017-09-27T09:07:49.000Z","categories_index":"Big Data","tags_index":"Ambari","author_index":"Kevin"},{"id":"ec9899f8bcf59da54011b603ddf86181","title":"OpenCC安装及错误处理","content":"Compile and Install OpenCC on Minimal CentOS 7測試過程在虛擬機中進行，使用vm搭建，操作系統版本CentOS Linux release 7.2.1511 (Core)，內核版本3.10.0-327.10.1.el7.x86_64。\nDownloading &amp; Uncompressing\nOpenCC代碼開源，公佈在GitHub上，地址 https://github.com/BYVoid/OpenCC，使用wegt命令下載，保存路徑爲/usr/local/src。\n執行命令\n123sudo wget https://github.com/BYVoid/OpenCC/archive/master.zip#重命名sudo mv master.zip opencc.zip\n文件是zip格式壓縮包，需要安裝unzip命令，否則會報錯\n1-bash: unzip: command not found\n\n執行命令\n1sudo yum -y install unzip\n執行unzip命令解壓到當前目錄\n123456sudo unzip opencc.zip[vagrant@opencc src]$ ls -lhtotal 1.8Mdrwxr-xr-x. 9 root root 4.0K Mar 10 21:57 OpenCC-master-rw-r--r--. 1 root root 1.8M Mar 22 21:05 opencc.zip[vagrant@opencc src]$\n\nCompilation\n編譯主要2步：make, make install，提示gcc 4.6 is required。\n安裝OpenCC需安裝以下依賴包\n1sudo yum install -y cmake gcc gcc-c++ doxygen\n爲/usr/lib/libopencc.so.2創建符號鏈接至/usr/lib64/libopencc.so.2\n以下是摸索過程\nError1\n進入目錄後，執行sudo make，報錯\n1cmake: command not found\n安裝cmake解決，執行命令\n1sudo yum install -y cmake\nError2\n再次執行sudo make，報錯\n1CMake Error: CMAKE_CXX_COMPILER not set\n因已安裝gcc，故安裝gcc-c++，執行命令\n1sudo yum install -y gcc-c++\nError3\n報錯\n1Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE)\n安裝doxygen，執行命令\n1sudo yum install -y doxygen\n再次執行sudo make，正常編譯\n執行make make install安裝\n123[vagrant@opencc OpenCC-master]$ which opencc/usr/bin/opencc[vagrant@opencc OpenCC-master]$\nError4\n執行命令opencc --help報錯\n1opencc: error while loading shared libraries: libopencc.so.2: cannot open shared object file: No such file or directory\n查找文件libopencc.so.2\n123[vagrant@opencc OpenCC-master]$ sudo find / -name libopencc.so.2/usr/local/src/OpenCC-master/build/rel/src/libopencc.so.2/usr/lib/libopencc.so.2\n根據繁体转简体，CentOS安装OpenCC，升级到gcc4.6，創建符號鏈接至&#x2F;usr&#x2F;lib64&#x2F;目錄下\n12345[vagrant@opencc OpenCC-master]$ sudo ln -s /usr/lib/libopencc.so.2 /usr/lib64/libopencc.so.2[vagrant@opencc OpenCC-master]$ opencc --versionOpen Chinese Convert (OpenCC) Command Line ToolVersion: 1.0.3[vagrant@opencc OpenCC-master]$\n成功安裝\nError5执行\n1opencc -i wiki.zh.text -o wiki.zh.text.jian -c zht2zhs.ini\n报错\n1PARSE JSON ERROR\nuse xxx.json file instead of xxx.ini\n1opencc -i wiki.zh.text -o wiki.zh.text.jian -c t2s.json\nexample dir -&gt; &#x2F;usr&#x2F;share&#x2F;opencc&#x2F;\nUsage\n123456789101112131415161718Usage:   opencc  [--noflush &lt;bool&gt;] [-i &lt;file&gt;] [-o &lt;file&gt;] [-c &lt;file&gt;] [--]           [--version] [-h]Options:   --noflush &lt;bool&gt;     Disable flush for every line   -i &lt;file&gt;,  --input &lt;file&gt;     Read original text from &lt;file&gt;.   -o &lt;file&gt;,  --output &lt;file&gt;     Write converted text to &lt;file&gt;.   -c &lt;file&gt;,  --config &lt;file&gt;     Configuration file   --,  --ignore_rest     Ignores the rest of the labeled arguments following this flag.   --version     Displays version information and exits.   -h,  --help     Displays usage information and exits.\n\n-i: 指定輸入文件\n-o: 指定轉換後的輸出文件\n-c: 指定配置文件，以何種形式轉換\n\n配置文件有如下幾種：\n\ns2t.json Simplified Chinese to Traditional Chinese 簡體到繁體\nt2s.json Traditional Chinese to Simplified Chinese 繁體到簡體\ns2tw.json Simplified Chinese to Traditional Chinese (Taiwan Standard) 簡體到臺灣正體\ntw2s.json Traditional Chinese (Taiwan Standard) to Simplified Chinese 臺灣正體到簡體\ns2hk.json Simplified Chinese to Traditional Chinese (Hong Kong Standard) 簡&gt;體到香港繁體（香港小學學習字詞表標準）\nhk2s.json Traditional Chinese (Hong Kong Standard) to Simplified Chinese 香&gt;港繁體（香港小學學習字詞表標準）到簡體\ns2twp.json Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom 簡體到繁體（臺灣正體標準）並轉* 換爲臺灣常用詞彙\ntw2sp.json Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom 繁體（臺灣正體標準）到簡* 體並轉換爲中國大陸常用詞彙\nt2tw.json Traditional Chinese (OpenCC Standard) to Taiwan Standard 繁體（OpenCC 標準）到臺灣正體\nt2hk.json Traditional Chinese (OpenCC Standard) to Hong Kong Standard 繁體（OpenCC 標準）到香港繁體（香港小學學習字詞表標準）\n\nUsage Example\nExample1\n使用配置文件tw2s將正體文件轉換爲簡體\n123456789101112[vagrant@opencc tmp]$ lstw.txt[vagrant@opencc tmp]$ cat tw.txt昨夜西風凋碧樹，獨上高樓，望盡天涯路[vagrant@opencc tmp]$ opencc -i tw.txt -o cn.txt -c tw2s[vagrant@opencc tmp]$ lscn.txt  tw.txt[vagrant@opencc tmp]$ cat cn.txt昨夜西风凋碧树，独上高楼，望尽天涯路[vagrant@opencc tmp]$ cat tw.txt昨夜西風凋碧樹，獨上高樓，望盡天涯路[vagrant@opencc tmp]$\nExample2\n使用管道符|\n12345[vagrant@opencc tmp]$ cat tw.txt昨夜西風凋碧樹，獨上高樓，望盡天涯路[vagrant@opencc tmp]$ cat tw.txt | opencc -c tw2s昨夜西风凋碧树，独上高楼，望尽天涯路[vagrant@opencc tmp]$\n\nReferences\n\nOpen Chinese Convert\n繁体转简体，CentOS安装OpenCC，升级到gcc4.6\nCompile and Install OpenCC on Minimal CentOS 7\n\n","slug":"opencc-installation-error","date":"2017-09-20T09:38:30.000Z","categories_index":"Linux","tags_index":"Linux,OpenCC,CentOS","author_index":"Kevin"},{"id":"f280d01f3b9ea21fcaf8001862fca181","title":"Pandora学习笔记","content":"Pandora学习笔记\n架构图\n\n\n控制台操作\n\n\n\n\n\n\n\n\n实时计算工作流：\n创建数据源\n在工作流编辑器中，我们首先看到的节点是数据源，这个节点用来接收用户的实时数据，也就是说，当这个节点被创建后，用户需要将自己的数据推送至这个数据源中，才可以继续进行下一步。\n\n\n\n定义字段及类型\n\n类型：\n\nstring\n\nfloat\n\nlong\n\ndate\n\nboolean\n\narray[string&#x2F;long&#x2F;float]\n\nmap\n\njsonstring\n\n\n\n\n创建计算任务\n\n\n计算的方式分为两种：标准SQL计算和自定义代码计算，它们两者可以并存，执行的顺序是先执行自定义代码计算，后执行标准SQL计算；在一个计算任务中，至少需要指定一种计算方式。\n\n使用UDF\n UDF是在SQL计算中使用的方法\n\n系统UDF\n  \n\n  系统默认提供了上百种udf，分别为：数学函数、日期函数、字符串函数、聚合函数和窗口函数，我们可以在工作流列表的右上角 UDF管理 中查看。\n\n自定义UDF\n  \n\n  \n\n  下载 UDF-java 项目工程，在 src&#x2F;main&#x2F;java&#x2F;com.pandora&#x2F; 目录下新建Class和方法，并在方法中编写udf逻辑，代码编写完成后，需要将这个工程打成Jar包并上传至Pandora，然后就可以注册并使用这个udf了。\n\n\n\n自定义计算（Plugin）- Java\n\n下载 -&gt; Plugin-Java.zip\n  \n\n编写输入&amp;输出类\n\n编写业务逻辑代码\n\n打包上传\n  \n\n\n\n数据导出\n\n导出数据至HTTP\n  \n\n导出数据至对象存储\n  \n\n导出数据至日志检索服务\n  \n\n导出数据至时序数据库\n  \n\n\n\n\n\n\n\n\n\n\n离线计算工作流：\n在工作流编辑器中，我们首先看到的节点是数据源，这个节点用来指定用户数据的位置，用户必须指定一个正确的数据所在地，并且成功加载后，才可以继续进行下一步。\n数据计算\n计算方式目前仅支持SQL。\n\n\n数据导出\n目前仅支持将数据导出到对象存储服务当中。\n\n\n\n七牛云官方教程： https://qiniu.github.io/pandora-docs/#/?id=pandora\n","slug":"pandora-notes","date":"2017-09-15T08:39:23.000Z","categories_index":"Big Data","tags_index":"Hadoop,Pandora","author_index":"Kevin"}]