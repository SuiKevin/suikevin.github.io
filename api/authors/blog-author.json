{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}},"post_list":[{"title":"windows系统刻录光盘教程_刻录系统光盘教程-CSDN博客【转载】","uid":"b99718bea3cc16756aa515dc86531783","slug":"windows-disc-burning","date":"2025-03-22T06:49:32.000Z","updated":"2025-03-22T06:50:58.359Z","comments":true,"path":"api/articles/windows-disc-burning.json","keywords":null,"cover":[],"text":"windows系统刻录光盘教程_刻录系统光盘教程-CSDN博客 Excerpt文章浏览阅读1.2k次，点赞9次，收藏7次。工作中如果有重要资料需要刻录成光盘该如...","permalink":"/post/windows-disc-burning","photos":[],"count_time":{"symbolsCount":989,"symbolsTime":"1 mins."},"categories":[{"name":"Tools","slug":"Tools","count":1,"path":"api/categories/Tools.json"}],"tags":[{"name":"Windows","slug":"Windows","count":1,"path":"api/tags/Windows.json"},{"name":"Disc Burning","slug":"Disc-Burning","count":1,"path":"api/tags/Disc-Burning.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"Compile and Install OpenCC on Minimal CentOS 7","uid":"34e2a32717145682320598ec6f8d1d99","slug":"ml-jieba-opencc","date":"2024-11-18T05:40:13.000Z","updated":"2025-03-22T06:20:52.899Z","comments":true,"path":"api/articles/ml-jieba-opencc.json","keywords":null,"cover":null,"text":"Compile and Install OpenCC on Minimal CentOS 7測試過程在虛擬機中進行，使用vm搭建，操作系統版本CentOS Li...","permalink":"/post/ml-jieba-opencc","photos":[],"count_time":{"symbolsCount":"4.5k","symbolsTime":"4 mins."},"categories":[{"name":"NLP","slug":"NLP","count":2,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":2,"path":"api/tags/NLP.json"},{"name":"Jieba","slug":"Jieba","count":2,"path":"api/tags/Jieba.json"},{"name":"Linux","slug":"Linux","count":3,"path":"api/tags/Linux.json"},{"name":"ML","slug":"ML","count":1,"path":"api/tags/ML.json"},{"name":"OpenCC","slug":"OpenCC","count":2,"path":"api/tags/OpenCC.json"},{"name":"CentOS","slug":"CentOS","count":2,"path":"api/tags/CentOS.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"Ubuntu/Python 结巴分词 + Word2Vec利用维基百科训练词向量","uid":"882d31fc168f9dee83d771cd41dd9d18","slug":"jieba-word2vec","date":"2024-11-18T05:40:13.000Z","updated":"2025-03-22T06:18:47.282Z","comments":true,"path":"api/articles/jieba-word2vec.json","keywords":null,"cover":null,"text":"Ubuntu/Python 结巴分词 + Word2Vec利用维基百科训练词向量结巴分词是一个跨语言的中文分词器，整体效果还算不错，功能也够用，这里直接用Pyt...","permalink":"/post/jieba-word2vec","photos":[],"count_time":{"symbolsCount":"10k","symbolsTime":"9 mins."},"categories":[{"name":"NLP","slug":"NLP","count":2,"path":"api/categories/NLP.json"}],"tags":[{"name":"NLP","slug":"NLP","count":2,"path":"api/tags/NLP.json"},{"name":"Jieba","slug":"Jieba","count":2,"path":"api/tags/Jieba.json"},{"name":"Word2Vec","slug":"Word2Vec","count":1,"path":"api/tags/Word2Vec.json"},{"name":"Linux","slug":"Linux","count":3,"path":"api/tags/Linux.json"},{"name":"Ubuntu","slug":"Ubuntu","count":1,"path":"api/tags/Ubuntu.json"},{"name":"Python","slug":"Python","count":1,"path":"api/tags/Python.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},{"title":"关于`SparkLivy`和`ZeppelinNotebook`访问`HDFS`时的多用户权限控制","uid":"fa8de5b59170093e2dea98ffe77b6754","slug":"sparklivy-zeppelin-hdfs-mutil-user-auth","date":"2017-12-09T09:29:08.000Z","updated":"2025-03-22T06:15:39.503Z","comments":true,"path":"api/articles/sparklivy-zeppelin-hdfs-mutil-user-auth.json","keywords":null,"cover":null,"text":"关于SparkLivy和ZeppelinNotebook访问HDFS时的多用户权限控制SparkLivy在Yarn上运行应用时，默认使用的用户是Livy。 Ze...","permalink":"/post/sparklivy-zeppelin-hdfs-mutil-user-auth","photos":[],"count_time":{"symbolsCount":"2.7k","symbolsTime":"2 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Zeppelin","slug":"Zeppelin","count":3,"path":"api/tags/Zeppelin.json"},{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"},{"name":"SparkLivy","slug":"SparkLivy","count":1,"path":"api/tags/SparkLivy.json"},{"name":"Zeppelin Notebook","slug":"Zeppelin-Notebook","count":1,"path":"api/tags/Zeppelin-Notebook.json"},{"name":"HDFS","slug":"HDFS","count":1,"path":"api/tags/HDFS.json"},{"name":"Mutil User","slug":"Mutil-User","count":1,"path":"api/tags/Mutil-User.json"},{"name":"Auth","slug":"Auth","count":1,"path":"api/tags/Auth.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"Hadoop生态部分组件介绍","uid":"f600e8de35fac4a36aec15d10c646ff1","slug":"hadoop-components","date":"2017-10-09T07:51:17.000Z","updated":"2025-03-22T06:52:43.174Z","comments":true,"path":"api/articles/hadoop-components.json","keywords":null,"cover":null,"text":"Apache Hadoop Apache Hadoop是一款支持数据密集型分布式应用程序并以Apache 2.0许可协议发布的开源软件框架。它支持在商品硬件构建...","permalink":"/post/hadoop-components","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Zeppelin","slug":"Zeppelin","count":3,"path":"api/tags/Zeppelin.json"},{"name":"Shiro","slug":"Shiro","count":2,"path":"api/tags/Shiro.json"},{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"},{"name":"Spark","slug":"Spark","count":1,"path":"api/tags/Spark.json"},{"name":"Livy","slug":"Livy","count":1,"path":"api/tags/Livy.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"Hadoop Notes","uid":"0d796f28558c1909e22d612dcdac7f4d","slug":"hadoop-notes","date":"2017-09-30T04:17:23.000Z","updated":"2025-03-22T06:04:32.006Z","comments":true,"path":"api/articles/hadoop-notes.json","keywords":null,"cover":[],"text":"Hadoop NotesNote1问题描述Yarn不能同时运行多个application 问题分析经观察ResourceManager UI 与执行命令 HAD...","permalink":"/post/hadoop-notes","photos":[],"count_time":{"symbolsCount":"1k","symbolsTime":"1 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"配置Zeppelin使用Apache Shiro进行鉴权（多用户登录）","uid":"98e85a349358aba091f9064f5f1ca497","slug":"ambari-zeppelin-shiro","date":"2017-09-27T10:51:57.000Z","updated":"2025-03-22T06:52:44.924Z","comments":true,"path":"api/articles/ambari-zeppelin-shiro.json","keywords":null,"cover":null,"text":"配置Zeppelin使用Apache Shiro进行鉴权（多用户登录）本人使用的Ambari搭建的Hadoop集群，Zeppelin也是Ambari管理的集群中...","permalink":"/post/ambari-zeppelin-shiro","photos":[],"count_time":{"symbolsCount":"5k","symbolsTime":"5 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Ambari","slug":"Ambari","count":2,"path":"api/tags/Ambari.json"},{"name":"Zeppelin","slug":"Zeppelin","count":3,"path":"api/tags/Zeppelin.json"},{"name":"Shiro","slug":"Shiro","count":2,"path":"api/tags/Shiro.json"},{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"Ambari安装Hadoop集群教程","uid":"26ca6bb559630836911bd4e42d633e9b","slug":"ambari-install","date":"2017-09-27T09:07:49.000Z","updated":"2025-03-22T06:52:46.375Z","comments":true,"path":"api/articles/ambari-install.json","keywords":null,"cover":null,"text":"Ambari安装Hadoop集群教程集群环境：阿里云服务器系统：Centos7 Linux master 3.10.0-514.16.1.el7.x86_64 ...","permalink":"/post/ambari-install","photos":[],"count_time":{"symbolsCount":"5k","symbolsTime":"5 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Ambari","slug":"Ambari","count":2,"path":"api/tags/Ambari.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"OpenCC安装及错误处理","uid":"ec9899f8bcf59da54011b603ddf86181","slug":"opencc-installation-error","date":"2017-09-20T09:38:30.000Z","updated":"2025-03-22T06:09:01.549Z","comments":true,"path":"api/articles/opencc-installation-error.json","keywords":null,"cover":null,"text":"Compile and Install OpenCC on Minimal CentOS 7測試過程在虛擬機中進行，使用vm搭建，操作系統版本CentOS Li...","permalink":"/post/opencc-installation-error","photos":[],"count_time":{"symbolsCount":"4.4k","symbolsTime":"4 mins."},"categories":[{"name":"Linux","slug":"Linux","count":1,"path":"api/categories/Linux.json"}],"tags":[{"name":"Linux","slug":"Linux","count":3,"path":"api/tags/Linux.json"},{"name":"OpenCC","slug":"OpenCC","count":2,"path":"api/tags/OpenCC.json"},{"name":"CentOS","slug":"CentOS","count":2,"path":"api/tags/CentOS.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"Pandora学习笔记","uid":"f280d01f3b9ea21fcaf8001862fca181","slug":"pandora-notes","date":"2017-09-15T08:39:23.000Z","updated":"2025-03-22T06:11:52.067Z","comments":true,"path":"api/articles/pandora-notes.json","keywords":null,"cover":[],"text":"Pandora学习笔记 架构图 控制台操作 实时计算工作流： 创建数据源 在工作流编辑器中，我们首先看到的节点是数据源，这个节点用来接收用户的实时数据，也就是说...","permalink":"/post/pandora-notes","photos":[],"count_time":{"symbolsCount":964,"symbolsTime":"1 mins."},"categories":[{"name":"Big Data","slug":"Big-Data","count":6,"path":"api/categories/Big-Data.json"}],"tags":[{"name":"Hadoop","slug":"Hadoop","count":5,"path":"api/tags/Hadoop.json"},{"name":"Pandora","slug":"Pandora","count":1,"path":"api/tags/Pandora.json"}],"author":{"name":"Kevin","slug":"blog-author","avatar":"/static/kevin_logo_x_s1.png","link":"/","description":"AI/FS/BD/WEB/New Media","socials":{"github":"https://github.com/SuiKevin","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}],"categories":4,"tags":37,"word_count":"36k","post_count":10}